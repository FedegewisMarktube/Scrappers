# MARKTUBE Scrapers Hub

This repository contains the central navigation hub for all MARKTUBE web scrapers.
It provides a unified interface for browsing locally stored, cleaned HTML pages generated by each scraper.
The project is deployed using GitHub Pages and operates entirely client-side without the need for a backend.

---

## Live Site

The site is published at:

```
https://fedegewismarktube.github.io/
```

The homepage presents the MARKTUBE branding and provides links to each scraper’s dataset.

---

## Project Structure

```
/
├── index.html                Main hub page
├── img/                      Images used on the landing page
├── ar.computrabajo/
│   ├── data/
│   │   ├── home.html         Entry point for Computrabajo HTML pages
│   │   ├── *.html            Cleaned static pages
│   │   └── CSS/              Local CSS resources
│   └── ...
└── (Additional scrapers will be added here)
```

Each scraper resides in its own folder to ensure separation and clarity.

---

## How the Hub Works

### Landing Page (`index.html`)

The landing page includes:

* The MARKTUBE visual identity
* A short description of the hub
* A set of buttons linking to each scraper directory

For example:

* Computrabajo Argentina → `ar.computrabajo/data/home.html`

All navigation is internal to the repository.

---

## Adding a New Scraper

To integrate a new scraper into the hub:

### 1. Create a new directory at the repository root

Example:

```
/zonajobs/
    /data/
        home.html
        *.html
        CSS/
```

### 2. Add a new navigation button to `index.html`

Within the `.buttons` section:

```html
<a class="btn" href="zonajobs/data/home.html">Zonajobs</a>
```

### 3. Commit and push to the `main` branch

GitHub Pages will automatically redeploy the site.

---

## Scraper Data Format

Each scraper follows a standardized structure:

```
/scraper_name/
    /data/
        home.html      Main entry file
        *.html         Static HTML pages extracted from the target site
        /CSS/          Local stylesheet files
```

All content is:

* Fully self-contained
* Free of external JavaScript
* Free of external tracking scripts
* Independent of third-party CDNs

This ensures fast loading, offline compatibility, and stable rendering under GitHub Pages.

---

## Deployment Overview

The site is deployed through GitHub Pages with the following configuration:

* Branch: `main`
* Folder: repository root (`/`)

GitHub Pages will automatically serve `index.html` as the homepage.

---

## Intended Use

The hub allows team members to:

* Review extracted HTML data
* Validate output quality across different scrapers
* Access offline versions of the scraped websites
* Use a centralized interface during development and testing

No installation or local server is required.

---

## Future Improvements

Potential enhancements include:

* Search functionality across scraper directories
* Support for additional scrapers
* Documentation extensions
* Optional filtering or categorization features

